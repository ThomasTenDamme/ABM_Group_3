{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import SingleGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.batchrunner import batch_run\n",
    "import multiprocessing\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve for preference of similar neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    x: fraction of similar neighbours\n",
    "    mu: optimal fraction of similar neighbours\n",
    "    sigma: acceptance range\n",
    "    \"\"\"\n",
    "    theta = np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_function(x, mu, sigma):\n",
    "    return np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "# Example usage:\n",
    "x_values = np.linspace(0, 1, 100)\n",
    "mu = 0.8  # Controls the peak location\n",
    "sigma = 0.3  # Controls the width\n",
    "\n",
    "y_values = gaussian_function(x_values, mu, sigma)\n",
    "\n",
    "plt.plot(x_values, y_values, color = '#63d298ff')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title(r'$\\theta$-Function with Peak at 0.8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Schelling\n",
    "from modules import property_value_from_gdf, update_interested_agents_concurrently, property_value_func_random, utility_func, price_func, income_func, property_value_from_gdf, property_value_quadrants, desirability_func, compute_similar_neighbours, property_value_equal, calculate_gi_star, price_func_cap\n",
    "\n",
    "# Function for simulation using the Singapore policy\n",
    "def schelling_singapore(num_runs, num_steps, burn_in_period, minority_pc, property_value_weight, alpha, mu_theta, sigma_theta, density, policy = True):\n",
    "\n",
    "    # initialize storage for parameters\n",
    "    overall_desirability_entropy = []\n",
    "    overall_agent_entropy = []\n",
    "    overall_utility = []\n",
    "\n",
    "    # run the model several times for the same parameter setting \n",
    "    for run in range(num_runs):\n",
    "        print('I am in round', run)\n",
    "        \n",
    "        # initialize model\n",
    "        models = Schelling(\n",
    "            property_value_func=property_value_from_gdf, # quadrants,\n",
    "            income_func=income_func,\n",
    "            desirability_func=desirability_func,\n",
    "            utility_func=utility_func,\n",
    "            price_func=price_func,\n",
    "            compute_similar_neighbours=compute_similar_neighbours,\n",
    "            calculate_gi_star = calculate_gi_star,\n",
    "            update_interested_agents_func = update_interested_agents_concurrently,\n",
    "            price_func_cap=price_func_cap,\n",
    "            policy_singapore=policy,\n",
    "            #height=20,\n",
    "            #width=20,\n",
    "            radius=1,\n",
    "            density=density,\n",
    "            minority_pc=minority_pc,\n",
    "            alpha=alpha,\n",
    "            income_scale=1.5, # the scale by which the income is higher than the property value\n",
    "            property_value_weight=property_value_weight,\n",
    "            mu_theta = mu_theta,\n",
    "            sigma_theta = sigma_theta,\n",
    "            seed=41)\n",
    "\n",
    "        # Run the model for a certain number of steps\n",
    "        for _ in range(num_steps):\n",
    "            models.step()\n",
    "\n",
    "        # call necessary data collectors\n",
    "        agent_data = models.datacollector.get_agent_vars_dataframe()\n",
    "        model_data_entropy = models.datacollector.get_model_vars_dataframe()\n",
    "    \n",
    "        # Compute mean and standard deviation of entropies over time per run\n",
    "        desirability_entropy = model_data_entropy['Desirability entropy'].to_numpy()\n",
    "        mean_desirability_entropy = np.mean(np.array(desirability_entropy[burn_in_period::]))\n",
    "        \n",
    "        agent_entropy = model_data_entropy['Agent entropy'].to_numpy()\n",
    "        mean_agent_entropy = np.mean(np.array(agent_entropy[burn_in_period::]))\n",
    "        # print(agent_entropy)\n",
    "        \n",
    "        # Compute mean and standard deviation of utility per time step over each agent \n",
    "        utility_mean = agent_data.groupby(level='Step')['Utility'].mean()\n",
    "        utility_std = agent_data.groupby(level='Step')['Utility'].std()\n",
    "        \n",
    "        # Compute mean and standard deviation of utility over time \n",
    "        utility_mean = pd.DataFrame(utility_mean).to_numpy()\n",
    "        utility_std = pd.DataFrame(utility_std).to_numpy()\n",
    "        mean_utility_interim = np.mean(utility_mean[burn_in_period::])\n",
    "\n",
    "        # Append all results to storage\n",
    "        overall_desirability_entropy.append(mean_desirability_entropy)\n",
    "        overall_agent_entropy.append(mean_agent_entropy)\n",
    "        overall_utility.append(mean_utility_interim)\n",
    "\n",
    "    return np.array(overall_desirability_entropy), np.array(overall_agent_entropy), np.array(overall_utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment settings\n",
    "num_iters = 100\n",
    "burn_in_period = 5\n",
    "model_steps = 30\n",
    "\n",
    "# model settings\n",
    "density = 0.8\n",
    "minority = 0.3\n",
    "alpha = 0.5\n",
    "property_value_weight = 0.1\n",
    "mu = 0.8\n",
    "sigma = 0.3\n",
    "\n",
    "# Run simulation\n",
    "singapore_policy_effect = schelling_singapore(num_iters, model_steps, burn_in_period, minority, property_value_weight, alpha, mu, sigma, density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simulation \n",
    "singapore_initial_results = np.column_stack((singapore_policy_effect[0], singapore_policy_effect[1], singapore_policy_effect[2]))\n",
    "\n",
    "# Save the stacked array to a CSV file\n",
    "#np.savetxt('singapore_policy_100_runs_2.csv', singapore_initial_results, delimiter=',', header='desirability_entropy, agent_entropy, utility') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No policy experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment settings\n",
    "num_iters = 100\n",
    "burn_in_period = 5\n",
    "model_steps = 30\n",
    "\n",
    "# model settings\n",
    "density = 0.8\n",
    "minority = 0.3\n",
    "alpha = 0.5\n",
    "property_value_weight = 0.1\n",
    "mu = 0.8\n",
    "sigma = 0.3\n",
    "\n",
    "# Run simulation\n",
    "no_policy_effect = schelling_singapore(num_iters, model_steps, burn_in_period, density, minority, alpha, property_value_weight, mu, sigma, policy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_policy_results = np.column_stack((no_policy_effect[0], no_policy_effect[1], no_policy_effect[2]))\n",
    "\n",
    "# Save the stacked array to a CSV file\n",
    "#np.savetxt('no_policy_result_100_runs.csv', no_policy_results, delimiter=',', header='desirability_entropy, agent_entropy, utility') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vienna experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules as modules\n",
    "import model as model\n",
    "from model import Schelling\n",
    "\n",
    "# Define function for simulation\n",
    "def schelling_vienna(num_runs, num_steps, burn_in_period, minority_pc, property_value_weight, alpha, mu_theta, sigma_theta, density, policy = True):\n",
    "\n",
    "    # initialize storage for parameters\n",
    "    overall_desirability_entropy = []\n",
    "    overall_agent_entropy = []\n",
    "    overall_utility = []\n",
    "\n",
    "    # run the model several times for the same parameter setting \n",
    "    for run in range(num_runs):\n",
    "        print('I am in round', run)\n",
    "        \n",
    "        # initialize model\n",
    "        models = Schelling(\n",
    "            property_value_func=modules.property_value_from_gdf, # quadrants,\n",
    "            income_func=modules.income_func,\n",
    "            desirability_func=modules.desirability_func,\n",
    "            utility_func=modules.utility_func,\n",
    "            price_func=modules.price_func,\n",
    "            compute_similar_neighbours=modules.compute_similar_neighbours,\n",
    "            calculate_gi_star = modules.calculate_gi_star,\n",
    "            update_interested_agents_func = modules.update_interested_agents_concurrently,\n",
    "            price_func_cap=modules.price_func_cap,\n",
    "            policy_vienna=policy,\n",
    "            #height=20,\n",
    "            #width=20,\n",
    "            radius=1,\n",
    "            density=density,\n",
    "            minority_pc=minority_pc,\n",
    "            alpha=alpha,\n",
    "            income_scale=1.5, # the scale by which the income is higher than the property value\n",
    "            property_value_weight=property_value_weight,\n",
    "            mu_theta = mu_theta,\n",
    "            sigma_theta = sigma_theta,\n",
    "            seed=42)\n",
    "\n",
    "        # Run the model for a certain number of steps\n",
    "        for _ in range(num_steps):\n",
    "            models.step()\n",
    "\n",
    "        # call necessary data collectors\n",
    "        agent_data = models.datacollector.get_agent_vars_dataframe()\n",
    "        model_data_entropy = models.datacollector.get_model_vars_dataframe()\n",
    "    \n",
    "        # Compute mean and standard deviation of entropies over time per run\n",
    "        desirability_entropy = model_data_entropy['Desirability entropy'].to_numpy()\n",
    "        mean_desirability_entropy = np.mean(np.array(desirability_entropy[burn_in_period::]))\n",
    "        \n",
    "        agent_entropy = model_data_entropy['Agent entropy'].to_numpy()\n",
    "        mean_agent_entropy = np.mean(np.array(agent_entropy[burn_in_period::]))\n",
    "        #print(agent_entropy)\n",
    "        \n",
    "        # Compute mean and standard deviation of utility per time step over each agent \n",
    "        utility_mean = agent_data.groupby(level='Step')['Utility'].mean()\n",
    "        utility_std = agent_data.groupby(level='Step')['Utility'].std()\n",
    "        \n",
    "        # Compute mean and standard deviation of utility over time \n",
    "        utility_mean = pd.DataFrame(utility_mean).to_numpy()\n",
    "        utility_std = pd.DataFrame(utility_std).to_numpy()\n",
    "        mean_utility_interim = np.mean(utility_mean[burn_in_period::])\n",
    "\n",
    "        # Append all results to storage\n",
    "        overall_desirability_entropy.append(mean_desirability_entropy)\n",
    "        overall_agent_entropy.append(mean_agent_entropy)\n",
    "        overall_utility.append(mean_utility_interim)\n",
    "\n",
    "    return np.array(overall_desirability_entropy), np.array(overall_agent_entropy), np.array(overall_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment settings\n",
    "num_iters = 100\n",
    "burn_in_period = 5\n",
    "model_steps = 30\n",
    "\n",
    "# model settings\n",
    "density = 0.8\n",
    "minority = 0.3\n",
    "alpha = 0.5\n",
    "property_value_weight = 0.1\n",
    "mu = 0.8\n",
    "sigma = 0.3\n",
    "\n",
    "# Run simulation\n",
    "vienna_policy_effect = schelling_vienna(num_iters, model_steps, burn_in_period, density, minority, alpha, property_value_weight, mu, sigma, policy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vienna_policy_effect = np.column_stack((vienna_policy_effect[0], vienna_policy_effect[1], vienna_policy_effect[2]))\n",
    "\n",
    "# Save the stacked array to a CSV file\n",
    "#np.savetxt('vienna_policy_result_100_runs2.csv', vienna_policy_effect, delimiter=',', header='desirability_entropy, agent_entropy, utility') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for initial experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data again (in case not newly generated)\n",
    "singapore_results = pd.read_csv('singapore_policy_100_runs_2.csv')\n",
    "vienna_results = pd.read_csv('vienna_policy_result_100_runs2.csv')\n",
    "random_results = pd.read_csv('no_policy_result_100_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desirability_vienna = vienna_results['# desirability_entropy'].to_numpy()\n",
    "desirability_singapore = singapore_results['# desirability_entropy'].to_numpy()\n",
    "desirability_random = random_results['# desirability_entropy'].to_numpy()\n",
    "\n",
    "agent_vienna = vienna_results[' agent_entropy'].to_numpy()\n",
    "agent_singapore = singapore_results[' agent_entropy'].to_numpy()\n",
    "agent_random = random_results[' agent_entropy'].to_numpy()\n",
    "\n",
    "utility_vienna = vienna_results[' utility'].to_numpy()\n",
    "utility_singapore = singapore_results[' utility'].to_numpy()\n",
    "utility_random = random_results[' utility'].to_numpy()\n",
    "\n",
    "plt.figure(dpi = 300, figsize = (10, 16))\n",
    "\n",
    "plt.subplot(311)\n",
    "# Create distribution plots for both datasets\n",
    "sns.histplot(desirability_vienna, kde=True, color='#63d298ff', label='Policy: Vienna', stat=\"density\")\n",
    "sns.histplot(desirability_singapore, kde=True, color='#fff176ff', label='Policy: Singapore', stat=\"density\")\n",
    "sns.histplot(desirability_random, kde=True, color='#ff5252ff', label='no policy', stat=\"density\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Desirability: Distribution Plots of different Policies')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(312)\n",
    "# Create distribution plots for both datasets\n",
    "sns.histplot(agent_vienna, kde=True, color='#63d298ff', label='Policy: Vienna', stat=\"density\")\n",
    "sns.histplot(agent_singapore, kde=True, color='#fff176ff', label='Policy: Singapore', stat=\"density\")\n",
    "sns.histplot(agent_random, kde=True, color='#ff5252ff', label='no policy', stat=\"density\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Agent entropy: Distribution Plots of different Policies')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.subplot(313)\n",
    "# Create distribution plots for both datasets\n",
    "sns.histplot(utility_vienna, kde=True, color='#63d298ff', label='Policy: Vienna', stat=\"density\")\n",
    "sns.histplot(utility_singapore, kde=True, color='#fff176ff', label='Policy: Singapore', stat=\"density\")\n",
    "sns.histplot(utility_random, kde=True, color='#ff5252ff', label='no policy', stat=\"density\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average utility: Distribution Plots of different Policies')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('Experiment_Results')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Sensitivity analysis; Varying Density "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sensitivity_analysis(model_class, fixed_params, variable_params, iterations, max_steps, data_collection_period, features_to_analyze, steps_to_skip=5):\n",
    "    # Perform the batch run with the specified parameters\n",
    "    results = batch_run(\n",
    "        model_class,\n",
    "        parameters={**fixed_params, **variable_params},\n",
    "        iterations=iterations,\n",
    "        max_steps=max_steps,\n",
    "        number_processes=None,\n",
    "        data_collection_period=data_collection_period,\n",
    "        display_progress=True\n",
    "    )\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Filter out the initial steps to skip\n",
    "    filtered_results = results_df[results_df['Step'] > steps_to_skip]\n",
    "    \n",
    "    # Prepare a dictionary to store the mean and std of the specified features\n",
    "    analysis_results = {}\n",
    "    \n",
    "    # Analyze each feature specified\n",
    "    for feature in features_to_analyze:\n",
    "        mean_feature = filtered_results.groupby(list(variable_params.keys()))[feature].mean().reset_index()\n",
    "        std_feature = filtered_results.groupby(list(variable_params.keys()))[feature].std().reset_index()\n",
    "        analysis_results[feature] = {\n",
    "            'mean': mean_feature,\n",
    "            'std': std_feature\n",
    "        }\n",
    "    \n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_analysis(feature_analysis, feature_name, variable_param_name):\n",
    "    mean_df = feature_analysis[feature_name]['mean']\n",
    "    std_df = feature_analysis[feature_name]['std']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    \n",
    "    # Plot the mean with standard deviation as error bars\n",
    "    plt.errorbar(mean_df[variable_param_name], mean_df[feature_name], \n",
    "                 yerr=std_df[feature_name], fmt='o', capsize=5, \n",
    "                 label=f'Average {feature_name}', color='#63d298ff')\n",
    "    \n",
    "    plt.title(f'Average {feature_name} vs {variable_param_name} with Standard Deviation')\n",
    "    plt.xlabel(variable_param_name)\n",
    "    #plt.ylim(0,1)\n",
    "    plt.ylabel(feature_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('diff_singapore_param_entropy_desirable.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_analysis_multiple(feature_analyses, feature_name, variable_param_name, labels=None):\n",
    "    \"\"\"\n",
    "    Plots the specified feature from multiple analyses on the same plot with different colors.\n",
    "    \n",
    "    Parameters:\n",
    "    feature_analyses (list of dict): List of feature analysis dictionaries containing 'mean' and 'std' data frames.\n",
    "    feature_name (str): Name of the feature to plot.\n",
    "    variable_param_name (str): Name of the variable parameter to plot on the X-axis.\n",
    "    labels (list of str): List of labels for the analyses. Defaults to None.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=300)\n",
    "    colors = ['#63d298ff', '#ff5252ff', '#fff176ff'] # plt.cm.rainbow(np.linspace(0, 1, len(feature_analyses)))\n",
    "    \n",
    "    for i, feature_analysis in enumerate(feature_analyses):\n",
    "        mean_df = feature_analysis[feature_name]['mean']\n",
    "        std_df = feature_analysis[feature_name]['std']\n",
    "        label = labels[i] if labels else f\"Analysis {i+1}\"\n",
    "        \n",
    "        # Plot the mean with standard deviation as error bars\n",
    "        plt.errorbar(mean_df[variable_param_name], mean_df[feature_name], \n",
    "                     yerr=std_df[feature_name], fmt='o', capsize=5, \n",
    "                     label=label, color=colors[i])\n",
    "    \n",
    "    plt.title(f'Average {feature_name} over {variable_param_name}')\n",
    "    plt.xlabel(variable_param_name)\n",
    "    plt.ylabel(feature_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('avarage_desirable_entropy_sigma_diff_policy.png')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `feature_analyses` is a list of dictionaries with the required structure\n",
    "# feature_analyses = [analysis1, analysis2, analysis3]\n",
    "# plot_feature_analysis_multiple(feature_analyses, 'feature_name', 'variable_param_name', labels=['Analysis 1', 'Analysis 2', 'Analysis 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "max_steps = 30\n",
    "\n",
    "# Example usage:\n",
    "fixed_params = {\n",
    "    \"property_value_func\": modules.property_value_from_gdf,\n",
    "    \"income_func\": modules.income_func,\n",
    "    \"desirability_func\": modules.desirability_func,\n",
    "    \"update_interested_agents_func\": modules.update_interested_agents_concurrently,\n",
    "    \"utility_func\": modules.utility_func,\n",
    "    \"price_func\": modules.price_func,\n",
    "    \"compute_similar_neighbours\": modules.compute_similar_neighbours,\n",
    "    \"calculate_gi_star\": modules.calculate_gi_star,\n",
    "    \"price_func_cap\": modules.price_func_cap,\n",
    "    \"height\": 20,\n",
    "    \"width\": 20,\n",
    "    \"policy_singapore_threshold\": 0.8,\n",
    "    \"density\": 0.8,\n",
    "    \"minority_pc\": 0.2,\n",
    "    \"alpha\": 0.5,\n",
    "    \"income_scale\": 1.5,\n",
    "    \"property_value_weight\": 0.35,\n",
    "    \"mu_theta\": 0.8,\n",
    "    \"sigma_theta\": 0.3\n",
    "}\n",
    "\n",
    "variable_params = {\n",
    "    'density': np.linspace(0, 1, 10),\n",
    "}\n",
    "\n",
    "features_to_analyze = [\"Utility\", \"Agent entropy\", \"Desirability entropy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis\n",
    "analysis_density_no_policy = run_sensitivity_analysis(\n",
    "    model_class=model.Schelling,\n",
    "    fixed_params=fixed_params,\n",
    "    variable_params=variable_params,\n",
    "    iterations=iterations,\n",
    "    max_steps=max_steps,\n",
    "    data_collection_period=8,\n",
    "    features_to_analyze=features_to_analyze\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_analysis(analysis_density_no_policy, \"Agent entropy\", \"density\")\n",
    "plot_feature_analysis(analysis_density_no_policy,\"Desirability entropy\", \"density\")\n",
    "plot_feature_analysis(analysis_density_no_policy, \"Utility\", \"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical testing of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV files\n",
    "data_vienna_policy = pd.read_csv(\"/Users/carokluin/Documents/CSM/Agent-Based-modelling/ABM_assignment.py/Mesa Schelling Visualization/vienna_policy_result_100_runs2.csv\")\n",
    "data_singapore_policy = pd.read_csv(\"/Users/carokluin/Documents/CSM/Agent-Based-modelling/ABM_assignment.py/Mesa Schelling Visualization/singapore_policy_100_runs_2.csv\")\n",
    "data_no_policy = pd.read_csv(\"/Users/carokluin/Documents/CSM/Agent-Based-modelling/ABM_assignment.py/Mesa Schelling Visualization/no_policy_result_100_runs.csv\")\n",
    "\n",
    "data_vienna_policy.columns = data_vienna_policy.columns.str.strip()\n",
    "data_no_policy.columns = data_no_policy.columns.str.strip()\n",
    "data_singapore_policy.columns = data_singapore_policy.columns.str.strip()\n",
    "\n",
    "# Metrics to compare\n",
    "metrics = [\"# desirability_entropy\", \"agent_entropy\", \"utility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ANOVA\n",
    "data_combined = pd.concat([data_vienna_policy.assign(policy='Vienna'),\n",
    "                           data_singapore_policy.assign(policy='Singapore'),\n",
    "                           data_no_policy.assign(policy='No Policy')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ANOVA model for each metric\n",
    "metrics = [\"desirability_entropy\", \"agent_entropy\", \"utility\"]\n",
    "anova_results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    model = smf.ols(f'{metric} ~ C(policy)', data=data_combined).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    anova_results[metric] = anova_table\n",
    "    print(f'ANOVA result for {metric}:')\n",
    "    print(anova_table)\n",
    "    print('\\n')\n",
    "\n",
    "    # Check normality of residuals\n",
    "    residuals = model.resid\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    sm.qqplot(residuals, line='s', ax=ax[0])\n",
    "    ax[0].set_title('Q-Q Plot')\n",
    "    \n",
    "    sns.histplot(residuals, kde=True, ax=ax[1])\n",
    "    ax[1].set_title('Histogram of Residuals')\n",
    "    plt.show()\n",
    "\n",
    "    # Shapiro-Wilk test\n",
    "    shapiro_test = stats.shapiro(residuals)\n",
    "    print('Shapiro-Wilk Test:')\n",
    "    print('Statistic:', shapiro_test.statistic)\n",
    "    print('p-value:', shapiro_test.pvalue)\n",
    "    print('\\n')\n",
    "\n",
    "    # Check homogeneity of variances\n",
    "    # Levene's Test\n",
    "    levene_test = stats.levene(\n",
    "        data_combined[data_combined['policy'] == 'Vienna'][metric],\n",
    "        data_combined[data_combined['policy'] == 'Singapore'][metric],\n",
    "        data_combined[data_combined['policy'] == 'No Policy'][metric]\n",
    "    )\n",
    "    print('Levene\\'s Test:')\n",
    "    print('Statistic:', levene_test.statistic)\n",
    "    print('p-value:', levene_test.pvalue)\n",
    "    print('\\n')\n",
    "\n",
    "    # Plot residuals vs. fitted values\n",
    "    fitted_vals = model.fittedvalues\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.scatterplot(x=fitted_vals, y=residuals, ax=ax)\n",
    "    ax.axhline(0, linestyle='--', color='r')\n",
    "    ax.set_xlabel('Fitted Values')\n",
    "    ax.set_ylabel('Residuals')\n",
    "    ax.set_title('Residuals vs. Fitted Values')\n",
    "    plt.show()\n",
    "\n",
    "    # Check independence of observations\n",
    "    # Durbin-Watson test\n",
    "    durbin_watson_test = sm.stats.durbin_watson(residuals)\n",
    "    print('Durbin-Watson Test:')\n",
    "    print('Statistic:', durbin_watson_test)\n",
    "    print('\\n')\n",
    "\n",
    "# Variance Inflation Factor (VIF) to check for multicollinearity (if applicable)\n",
    "variables = model.model.exog\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['VIF'] = [variance_inflation_factor(variables, i) for i in range(variables.shape[1])]\n",
    "vif_data['variable'] = model.model.exog_names\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Kruskall Wallis for when assumptions are not met; desirability and utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract groups\n",
    "groups = [data_combined[data_combined['policy'] == policy]['utility'].values for policy in data_combined['policy'].unique()]\n",
    "\n",
    "# Perform Kruskal-Wallis Test\n",
    "statistic, p_value = kruskal(*groups)\n",
    "\n",
    "print(f\"Kruskal-Wallis H test statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [data_combined[data_combined['policy'] == policy]['desirability_entropy'].values for policy in data_combined['policy'].unique()]\n",
    "# Perform Kruskal-Wallis Test\n",
    "statistic, p_value = kruskal(*groups)\n",
    "\n",
    "print(f\"Kruskal-Wallis H test statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# singificant p-value indicates differences between groups, so post hoc analysis \n",
    "One commonly used post-hoc test for non-parametric data is the Dunnâ€™s test with a Bonferroni correction for multiple comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(data_combined, val_col='utility', group_col='policy', p_adjust='bonferroni')\n",
    "\n",
    "print(dunn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dunn_results = sp.posthoc_dunn(data_combined, val_col='desirability_entropy', group_col='policy', p_adjust='bonferroni')\n",
    "\n",
    "print(dunn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the ANOVA model\n",
    "model = smf.ols('agent_entropy ~ C(policy)', data=data_combined).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=data_combined['agent_entropy'], groups=data_combined['policy'], alpha=0.05)\n",
    "\n",
    "# Print Tukey HSD test summary\n",
    "print(tukey)\n",
    "\n",
    "# Plot the results\n",
    "tukey.plot_simultaneous()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABM-Notebooks-0-1-OzA5lFMJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
