{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if filename already exists, if so add number\n",
    "def check_filename(filename):\n",
    "    filename = \"figs/\" +  filename\n",
    "    if os.path.exists(filename + \".png\"):\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_filename = filename + \"_\" + str(i)\n",
    "            if os.path.exists(new_filename + \".png\"):\n",
    "                i += 1\n",
    "            else:\n",
    "                return new_filename + \".png\"\n",
    "    else:\n",
    "        return filename + \".png\"\n",
    "    \n",
    "# save figure\n",
    "def save_figure(fig, filename):\n",
    "    filename = check_filename(filename)\n",
    "    fig.savefig(filename)\n",
    "    print(f'Figure saved as {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satelli sampling means variance based sampling, but not a good measure for non-uniform distribution. Advantage: just extends series further if you want to increase number of samples\n",
    "Parallelization of sampling --> batch run (concurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    x: fraction of similar neighbours\n",
    "    mu: optimal fraction of similar neighbours\n",
    "    sigma: acceptance range\n",
    "    \"\"\"\n",
    "    theta = np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_function(x, mu, sigma):\n",
    "    return np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "# Example usage:\n",
    "x_values = np.linspace(0, 1, 100)\n",
    "mu = 0.8  # Peak in the middle\n",
    "sigma = 0.5  # Controls the width\n",
    "\n",
    "y_values = gaussian_function(x_values, mu, sigma)\n",
    "\n",
    "# You can plot the function to visualize it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title(f'Gaussian Function with Peak at {mu}')\n",
    "plt.show()\n",
    "\n",
    "#save_figure(plt, f'Gaussian Function with Peak at {mu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobol Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules as modules\n",
    "import model as model\n",
    "from model import Schelling\n",
    "\n",
    "def schelling_SA(num_runs, num_steps, burn_in_period, minority_pc, property_value_weight, alpha, mu_theta, sigma_theta, density):\n",
    "\n",
    "    # initialize storage for parameters\n",
    "    overall_desirability_entropy = []\n",
    "    overall_agent_entropy = []\n",
    "    overall_utility = []\n",
    "\n",
    "    # run the model several times for the same parameter setting \n",
    "    for _ in range(num_runs):\n",
    "\n",
    "        # initialize model\n",
    "        models = Schelling(\n",
    "            property_value_func=modules.property_value_from_gdf,\n",
    "            income_func=modules.income_func,\n",
    "            desirability_func=modules.desirability_func,\n",
    "            utility_func=modules.utility_func,\n",
    "            price_func=modules.price_func,\n",
    "            compute_similar_neighbours=modules.compute_similar_neighbours,\n",
    "            calculate_gi_star = modules.calculate_gi_star,\n",
    "            update_interested_agents_func = modules.update_interested_agents_concurrently,\n",
    "            price_func_cap=modules.price_func_cap,\n",
    "            height=20,\n",
    "            width=20,\n",
    "            radius=1,\n",
    "            density=density,\n",
    "            minority_pc=minority_pc,\n",
    "            alpha=alpha,\n",
    "            income_scale=1.5, # the scale by which the income is higher than the property value\n",
    "            property_value_weight=property_value_weight,\n",
    "            mu_theta = mu_theta,\n",
    "            sigma_theta = sigma_theta,\n",
    "            seed=42)\n",
    "\n",
    "        # Run the model for a certain number of steps\n",
    "        for _ in range(num_steps):\n",
    "            models.step()\n",
    "\n",
    "        # call necessary data collectors\n",
    "        agent_data = models.datacollector.get_agent_vars_dataframe()\n",
    "        model_data_entropy = models.datacollector.get_model_vars_dataframe()\n",
    "    \n",
    "        # Compute mean and standard deviation of entropies over time per run\n",
    "        desirability_entropy = model_data_entropy['Desirability entropy'].to_numpy()\n",
    "        # desirability_entropy_std = model_data_entropy['Desirability entropy'].std()\n",
    "        mean_desirability_entropy = np.mean(desirability_entropy[burn_in_period::])\n",
    "    \n",
    "        agent_entropy = model_data_entropy['Agent entropy'].to_numpy()\n",
    "        # agent_entropy_std = model_data_entropy['Agent entropy'].std()\n",
    "        mean_agent_entropy = np.mean(agent_entropy[burn_in_period::])\n",
    "        \n",
    "        # Compute mean and standard deviation of utility per time step over each agent \n",
    "        utility_mean = agent_data.groupby(level='Step')['Utility'].mean()\n",
    "        #utility_std = agent_data.groupby(level='Step')['Utility'].std()\n",
    "    \n",
    "        # Compute mean and standard deviation of utility over time \n",
    "        utility_mean = pd.DataFrame(utility_mean).to_numpy()\n",
    "        #utility_std = pd.DataFrame(utility_std).to_numpy()\n",
    "        mean_utility_interim = np.mean(utility_mean[burn_in_period::])\n",
    "\n",
    "        # Append all results to storage\n",
    "        overall_desirability_entropy.append(mean_desirability_entropy)\n",
    "        overall_agent_entropy.append(mean_agent_entropy)\n",
    "        overall_utility.append(mean_utility_interim)\n",
    "\n",
    "    mean_desirability = np.mean(overall_desirability_entropy)\n",
    "    mean_agent = np.mean(overall_agent_entropy)\n",
    "    mean_utility = np.mean(overall_utility)\n",
    "\n",
    "    return mean_desirability, mean_agent, mean_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Problem definition\n",
    "problem = {\n",
    "    'num_vars': 6,\n",
    "    'names': ['density', 'minority_pc', 'property_value_weight', 'alpha', 'mu_theta', 'sigma_theta'],\n",
    "    'bounds': [[0,1], [0,1], [0,1], [0,1], [0,1], [0,1]]\n",
    "}\n",
    "\n",
    "# Step 2: Generate samples \n",
    "samples = saltelli.sample(problem, 25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: evaluate the model under the different parameter settings \n",
    "# Define settings \n",
    "iterations = 30\n",
    "model_steps = 30\n",
    "burn_in = 5\n",
    "\n",
    "# Initialize storage for measures\n",
    "result_desirability = np.zeros([samples.shape[0]])\n",
    "result_agent = np.zeros([samples.shape[0]])\n",
    "result_utility = np.zeros([samples.shape[0]])\n",
    "\n",
    "# load csv files\n",
    "#isExist = os.path.exists('results/sa_desirability.csv')\n",
    "if os.path.exists('results/sa_desirability.csv'):\n",
    "    result_desirability = pd.read_csv('results/sa_desirability.csv', index_col=0).to_numpy().flatten()\n",
    "    result_agent = pd.read_csv('results/sa_agent.csv', index_col=0).to_numpy().flatten()\n",
    "    result_utility = pd.read_csv('results/sa_utility.csv', index_col=0).to_numpy().flatten()\n",
    "\n",
    "    # find the last row that is not 0.0\n",
    "    last_row = np.where(result_desirability == 0.0)[0][0]\n",
    "else:\n",
    "    last_row = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(result_desirability, result_agent, result_utility):\n",
    "    print('Saving model...')\n",
    "    pd.DataFrame(result_desirability).to_csv('results/sa_desirability.csv')\n",
    "    pd.DataFrame(result_agent).to_csv('results/sa_agent.csv')\n",
    "    pd.DataFrame(result_utility).to_csv('results/sa_utility.csv')\n",
    "    print('Model saved')\n",
    "    return\n",
    "\n",
    "def evaluate_model(samples, result_desirability, result_agent, result_utility, iterations, model_steps, burn_in, last_row=0):\n",
    "    for i, X in enumerate(samples):\n",
    "        print(f'Iteration {i+1} out of {samples.shape[0]}')\n",
    "        if i < last_row:\n",
    "            print('Already computed')\n",
    "        else:\n",
    "            results = schelling_SA(iterations, model_steps, burn_in, *X)\n",
    "            result_desirability[i] = results[0]\n",
    "            result_agent[i] = results[1]\n",
    "            result_utility[i] = results[2]\n",
    "            save_model(result_desirability, result_agent, result_utility)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mparallel_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_desirability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_utility\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_row\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mparallel_evaluate_model\u001b[0;34m(samples, result_desirability, result_agent, result_utility, iterations, model_steps, burn_in, last_row)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning in parallel...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m pool \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mPool(mp\u001b[38;5;241m.\u001b[39mcpu_count())\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_desirability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_utility\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_row\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      9\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# run evaluate model in parallel\n",
    "def parallel_evaluate_model(samples, result_desirability, result_agent, result_utility, iterations, model_steps, burn_in, last_row):\n",
    "    print('Running in parallel...')\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    pool.starmap(evaluate_model, [(samples, result_desirability, result_agent, result_utility, iterations, model_steps, burn_in, last_row)])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Done')\n",
    "    return\n",
    "\n",
    "parallel_evaluate_model(samples, result_desirability, result_agent, result_utility, iterations, model_steps, burn_in, last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: analyse results\n",
    "Si_desirability = sobol.analyze(problem, result_desirability, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_agent = sobol.analyze(problem, result_agent, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_utility = sobol.analyze(problem, result_utility, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plots\n",
    "# Set params generally for all plots\n",
    "params = ['Density', 'Minority Percentage', 'Weight: property value', r\"$\\alpha$\", r\"$\\mu$\", r\"$\\sigma$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots for first and total order \n",
    "# First we do that for desirability\n",
    "S1_desirability = Si_desirability['S1']\n",
    "S1_conf_desirability = Si_desirability['S1_conf']\n",
    "\n",
    "ST_desirability = Si_desirability['ST']\n",
    "ST_conf_desirability = Si_desirability['ST_conf']\n",
    "\n",
    "# Convert confidence intervals to errors (assuming symmetrical errors)\n",
    "S1_err_desirability = np.array(S1_conf_desirability)\n",
    "ST_err_desirability = np.array(ST_conf_desirability)\n",
    "\n",
    "# Second for agent entropy\n",
    "S1_agent = Si_agent['S1']\n",
    "S1_conf_agent = Si_agent['S1_conf']\n",
    "\n",
    "ST_agent = Si_agent['ST']\n",
    "ST_conf_agent = Si_agent['ST_conf']\n",
    "\n",
    "# Convert confidence intervals to errors (assuming symmetrical errors)\n",
    "S1_err_agent = np.array(S1_conf_agent)\n",
    "ST_err_agent = np.array(ST_conf_agent)\n",
    "\n",
    "# Finally for utility\n",
    "S1_utility = Si_utility['S1']\n",
    "S1_conf_utility = Si_utility['S1_conf']\n",
    "\n",
    "ST_utility = Si_utility['ST']\n",
    "ST_conf_utility = Si_utility['ST_conf']\n",
    "\n",
    "# Convert confidence intervals to errors (assuming symmetrical errors)\n",
    "S1_err_utility = np.array(S1_conf_utility)\n",
    "ST_err_utility = np.array(ST_conf_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot settings\n",
    "# Bar width\n",
    "bar_width = 0.2\n",
    "\n",
    "# Positions of the bars\n",
    "r1 = np.arange(len(params))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axs = plt.subplots(3, 1, dpi=300, figsize=(6, 16))\n",
    "\n",
    "# Desirability subplot\n",
    "axs[0].bar(r1, S1_desirability, yerr=S1_err_desirability, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "axs[0].bar(r2, ST_desirability, yerr=ST_err_desirability, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "#axs[0].set_xlabel('Parameters', fontsize=10)\n",
    "axs[0].set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "axs[0].set_title('Desirability', fontweight='bold', fontsize=15)\n",
    "axs[0].set_xticks([]) \n",
    "#axs[0].set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "#axs[0].set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "axs[0].legend()\n",
    "\n",
    "# Segregation subplot\n",
    "axs[1].bar(r1, S1_agent, yerr=S1_err_agent, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "axs[1].bar(r2, ST_agent, yerr=ST_err_agent, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "#axs[1].set_xlabel('Parameters', fontsize=10)\n",
    "axs[1].set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "axs[1].set_title('Segregation', fontweight='bold', fontsize=15)\n",
    "axs[1].set_xticks([]) \n",
    "#axs[1].set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "#axs[1].set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "axs[1].legend()\n",
    "\n",
    "# Utility subplot\n",
    "axs[2].bar(r1, S1_utility, yerr=S1_err_utility, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "axs[2].bar(r2, ST_utility, yerr=ST_err_utility, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "axs[2].set_xlabel('Parameters', fontsize=10)\n",
    "axs[2].set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "axs[2].set_title('Utility', fontweight='bold', fontsize=15)\n",
    "axs[2].set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "axs[2].set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "save_figure(plt, f'Utility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sensitivity analysis results\n",
    "pairs = [\n",
    "    '(Density, Minority percentage)', \n",
    "    '(Density, Weight: property value)', \n",
    "    r'(Density, $\\alpha$)', \n",
    "    r'(Density, $\\mu$)', \n",
    "    r'(Density, $\\sigma$)', \n",
    "    '(Minority percentage, Weight: property value)', \n",
    "    r'(Minority percentage, $\\alpha$)', \n",
    "    r'(Minority percentage, $\\mu$)', \n",
    "    r'(Minority percentage, $\\sigma$)', \n",
    "    r'(Weight: property value, $\\alpha$)', \n",
    "    r'(Weight: property value, $\\mu$)', \n",
    "    r'(Weight: property value, $\\sigma$)', \n",
    "    r'($\\alpha$, $\\mu$)', \n",
    "    r'($\\alpha$, $\\sigma$)', \n",
    "    r'($\\mu$, $\\sigma$)'\n",
    "]\n",
    "# Three sets of S2 values and their confidence intervals\n",
    "S2_desirability = np.array(Si_desirability['S2'])\n",
    "S2_desirability = S2_desirability[~np.isnan(S2_desirability)]\n",
    "S2_conf_desirability = np.array(Si_desirability['S2_conf'])\n",
    "S2_conf_desirability = S2_conf_desirability[~np.isnan(S2_conf_desirability)]\n",
    "\n",
    "S2_agent = np.array(Si_agent['S2'])\n",
    "S2_agent = S2_agent[~np.isnan(S2_agent)]\n",
    "S2_conf_agent = np.array(Si_agent['S2_conf'])\n",
    "S2_conf_agent = S2_conf_agent[~np.isnan(S2_conf_agent)]\n",
    "\n",
    "S2_utility = np.array(Si_utility['S2'])\n",
    "S2_utility = S2_utility[~np.isnan(S2_utility)]\n",
    "S2_conf_utility = np.array(Si_utility['S2_conf'])\n",
    "S2_conf_utility = S2_conf_utility[~np.isnan(S2_conf_utility)]\n",
    "\n",
    "# Convert confidence intervals to errors (assuming symmetrical errors)\n",
    "S2_1_err = np.array(S2_conf_desirability)\n",
    "S2_2_err = np.array(S2_conf_agent)\n",
    "S2_3_err = np.array(S2_conf_utility)\n",
    "\n",
    "# Ensure all arrays are of the same length\n",
    "assert len(pairs) == len(S2_desirability) == len(S2_conf_desirability) == len(S2_agent) == len(S2_conf_agent) == len(S2_utility) == len(S2_conf_utility), \"All input arrays must have the same length\"\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.2\n",
    "\n",
    "# Positions of the bars\n",
    "positions = np.arange(len(pairs))\n",
    "r1 = positions - bar_width\n",
    "r2 = positions\n",
    "r3 = positions + bar_width\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(dpi = 300, figsize=(14, 8))\n",
    "\n",
    "# Plot with error bars\n",
    "bars1 = ax.bar(r1, S2_desirability, yerr=S2_1_err, capsize=5, color='purple', width=bar_width, edgecolor='grey', label='S2: Desirability')\n",
    "bars2 = ax.bar(r2, S2_agent, yerr=S2_2_err, capsize=5, color='orange', width=bar_width, edgecolor='grey', label='S2: Segregation')\n",
    "bars3 = ax.bar(r3, S2_utility, yerr=S2_3_err, capsize=5, color='green', width=bar_width, edgecolor='grey', label='S2: Utility')\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('Parameter Pairs', fontsize=10)\n",
    "ax.set_ylabel('Sensitivity Indices (S2)', fontsize=10)\n",
    "ax.set_title('Second-Order Sensitivity Analysis Results', fontweight='bold', fontsize=15)\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(plt, f'Second-Order Sensitivity Analysis Results')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desirability \n",
    "fig, ax = plt.subplots(dpi = 300, figsize=(10, 8))\n",
    "plt.bar(r1, S1_desirability, yerr=S1_err_desirability, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "plt.bar(r2, ST_desirability, yerr=ST_err_desirability, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "ax.set_xlabel('Parameters', fontsize=10)\n",
    "ax.set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "ax.set_title('Desirability', fontweight='bold', fontsize=15)\n",
    "#axs[0].set_xticks([]) \n",
    "ax.set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "ax.set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "save_figure(plt, f'Desirability')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregation subplot\n",
    "fig, ax = plt.subplots(dpi = 300, figsize=(10, 8))\n",
    "ax.bar(r1, S1_agent, yerr=S1_err_agent, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "ax.bar(r2, ST_agent, yerr=ST_err_agent, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "ax.set_xlabel('Parameters', fontsize=10)\n",
    "ax.set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "ax.set_title('Segregation', fontweight='bold', fontsize=15)\n",
    "#ax.set_xticks([]) \n",
    "ax.set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "ax.set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "save_figure(plt, f'Segregation')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility subplot\n",
    "fig, ax = plt.subplots(dpi = 300, figsize=(10, 8))\n",
    "ax.bar(r1, S1_utility, yerr=S1_err_utility, capsize=5, color='#63d298ff', width=bar_width, edgecolor='grey', label='First order')\n",
    "ax.bar(r2, ST_utility, yerr=ST_err_utility, capsize=5, color='#fff176ff', width=bar_width, edgecolor='grey', label='Total order')\n",
    "ax.set_xlabel('Parameters', fontsize=10)\n",
    "ax.set_ylabel('Sensitivity Indices', fontsize=10)\n",
    "ax.set_title('Utility', fontweight='bold', fontsize=15)\n",
    "ax.set_xticks([r + bar_width/2 for r in range(len(params))])\n",
    "ax.set_xticklabels(params, rotation=45, ha='right', fontsize=12)\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABM-Notebooks-0-1-OzA5lFMJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
